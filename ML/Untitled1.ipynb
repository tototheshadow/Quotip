{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XPyQxn41uiLx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, GlobalAveragePooling1D, Flatten\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2CQLZiokvAHq"
      },
      "outputs": [],
      "source": [
        "train_sentences = []\n",
        "train_labels = []\n",
        "with open(\"./dataset/train.txt\") as f:\n",
        "    for items in f:\n",
        "        item = items.split(\";\")\n",
        "        train_sentences.append(item[0])\n",
        "        train_labels.append(item[1].rstrip())\n",
        "\n",
        "test_sentences = []\n",
        "test_labels = []\n",
        "with open(\"./dataset/test.txt\") as f:\n",
        "    for items in f:\n",
        "        item = items.split(\";\")\n",
        "        test_sentences.append(item[0])\n",
        "        test_labels.append(item[1].rstrip())\n",
        "\n",
        "val_sentences = []\n",
        "val_labels = []\n",
        "with open(\"./dataset/val.txt\") as f:\n",
        "    for items in f:\n",
        "        item = items.split(\";\")\n",
        "        val_sentences.append(item[0])\n",
        "        val_labels.append(item[1].rstrip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmugPE9B7Fjq",
        "outputId": "245e32ce-d9ce-4fc5-c56b-a05690b36ade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'joy', 'love', 'fear', 'anger', 'surprise', 'sadness'}\n"
          ]
        }
      ],
      "source": [
        "print(set(train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCls-V8NvEdn",
        "outputId": "5b79f803-e90f-4223-daa2-a47c0c5cc1f5"
      },
      "outputs": [],
      "source": [
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000\n",
        "vocab_size = 5000\n",
        "max_length = 32\n",
        "embedding_dim = 64\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "\n",
        "train_seq = tokenizer.texts_to_sequences(train_sentences)\n",
        "\n",
        "train_padded = pad_sequences(train_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2000\n",
            "(2000, 32)\n"
          ]
        }
      ],
      "source": [
        "# tokenizer.fit_on_texts(val_sentences)\n",
        "val_seq = tokenizer.texts_to_sequences(val_sentences)\n",
        "val_padded = pad_sequences(val_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "val_padded = np.array(val_padded)\n",
        "\n",
        "print(len(val_seq))\n",
        "print(val_padded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# label\n",
        "labels = list(train_labels)\n",
        "label_tokenizer = Tokenizer()\n",
        "label_tokenizer.fit_on_texts(labels)\n",
        "\n",
        "train_label_seq = np.array(label_tokenizer.texts_to_sequences(train_labels))\n",
        "val_label_seq = np.array(label_tokenizer.texts_to_sequences(val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 64)          320000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              66048     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 7)                 455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 394,759\n",
            "Trainable params: 394,759\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(7, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "# encode = OneHotEncoder()\n",
        "\n",
        "# onehot_train_label = encode.fit_transform(train_label_seq)\n",
        "# onehot_val_label = encode.transform(val_label_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FCETql09C04I"
      },
      "outputs": [],
      "source": [
        "onehot_train_label = np.squeeze(tf.one_hot(train_label_seq,7).numpy())\n",
        "onehot_val_label = np.squeeze(tf.one_hot(val_label_seq,7).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeKylziRDeWD",
        "outputId": "a7468138-c86e-436e-c0e2-d39197d7f8f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print(onehot_train_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5o9tR0u4vVpp"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'Adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RryC2eWdvcR3",
        "outputId": "274f79a7-cd91-48ff-9d3a-d41a46688e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "500/500 [==============================] - 15s 25ms/step - loss: 1.2052 - accuracy: 0.5314 - val_loss: 0.5736 - val_accuracy: 0.8060\n",
            "Epoch 2/10\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.3244 - accuracy: 0.8873 - val_loss: 0.2887 - val_accuracy: 0.8925\n",
            "Epoch 3/10\n",
            "500/500 [==============================] - 15s 30ms/step - loss: 0.1664 - accuracy: 0.9383 - val_loss: 0.3020 - val_accuracy: 0.8995\n",
            "Epoch 4/10\n",
            "500/500 [==============================] - 14s 29ms/step - loss: 0.1232 - accuracy: 0.9547 - val_loss: 0.2972 - val_accuracy: 0.8995\n",
            "Epoch 5/10\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.0943 - accuracy: 0.9646 - val_loss: 0.3107 - val_accuracy: 0.8975\n",
            "Epoch 6/10\n",
            "500/500 [==============================] - 15s 29ms/step - loss: 0.0800 - accuracy: 0.9701 - val_loss: 0.3388 - val_accuracy: 0.8960\n",
            "Epoch 7/10\n",
            "500/500 [==============================] - 16s 32ms/step - loss: 0.0682 - accuracy: 0.9741 - val_loss: 0.3495 - val_accuracy: 0.8995\n",
            "Epoch 8/10\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.0509 - accuracy: 0.9809 - val_loss: 0.4183 - val_accuracy: 0.8910\n",
            "Epoch 9/10\n",
            "500/500 [==============================] - 16s 33ms/step - loss: 0.0527 - accuracy: 0.9804 - val_loss: 0.4051 - val_accuracy: 0.89157 - accu - ETA: 1s\n",
            "Epoch 10/10\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.0406 - accuracy: 0.9852 - val_loss: 0.4348 - val_accuracy: 0.8890\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "\n",
        "history = model.fit(train_padded, onehot_train_label, epochs=num_epochs, validation_data=(val_padded, onehot_val_label), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "id": "ZdO6YvC7vlko",
        "outputId": "d7a958fb-2117-4faa-e896-69ecf30e3f17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None,).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None,).\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"d:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"d:\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 213, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" (type Sequential).\n    \n    Input 0 of layer \"bidirectional_1\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 64)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=string)\n      • training=False\n      • mask=None\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-44-048ff0eac68c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'i feel good'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"d:\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 213, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" (type Sequential).\n    \n    Input 0 of layer \"bidirectional_1\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 64)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=string)\n      • training=False\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "predicted = model.predict(np.array(['i feel good']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(val_padded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "or2stFr74sGV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./saved_models/1653681532\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./saved_models/1653681532\\assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000221D8A48250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000221D8A48BE0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "saved_model_path = './saved_models/{}'.format(int(time.time()))\n",
        "\n",
        "tf.keras.models.save_model(model, saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "saved_model_path = \"./saved_models/models.h5\"\n",
        "\n",
        "model.save(saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 64)          320000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              66048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 394,694\n",
            "Trainable params: 394,694\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "savedModel=load_model('./saved_models/models.h5')\n",
        "savedModel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-28 03:02:11.208731: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
            "2022-05-28 03:02:11.209145: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2022-05-28 03:02:26.916560: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\n",
            "2022-05-28 03:02:26.916873: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2022-05-28 03:02:26.962074: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: MIHOK\n",
            "2022-05-28 03:02:26.962456: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: MIHOK\n",
            "2022-05-28 03:02:26.997326: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "!tensorflowjs_converter --input_format=keras_saved_model \\\n",
        "    ./saved_models/1653681532 \\\n",
        "        ./saved_models/linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "json_string = model.to_json()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, null], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"embedding_input\"}}, {\"class_name\": \"Embedding\", \"config\": {\"name\": \"embedding\", \"trainable\": true, \"batch_input_shape\": [null, null], \"dtype\": \"float32\", \"input_dim\": 5000, \"output_dim\": 64, \"embeddings_initializer\": {\"class_name\": \"RandomUniform\", \"config\": {\"minval\": -0.05, \"maxval\": 0.05, \"seed\": null}}, \"embeddings_regularizer\": null, \"activity_regularizer\": null, \"embeddings_constraint\": null, \"mask_zero\": false, \"input_length\": null}}, {\"class_name\": \"Bidirectional\", \"config\": {\"name\": \"bidirectional\", \"trainable\": true, \"dtype\": \"float32\", \"layer\": {\"class_name\": \"LSTM\", \"config\": {\"name\": \"lstm\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": false, \"return_state\": false, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"time_major\": false, \"units\": 64, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"recurrent_initializer\": {\"class_name\": \"Orthogonal\", \"config\": {\"gain\": 1.0, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"unit_forget_bias\": true, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"implementation\": 2}}, \"merge_mode\": \"concat\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 6, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.7.0\", \"backend\": \"tensorflow\"}\n"
          ]
        }
      ],
      "source": [
        "print(json_string)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
